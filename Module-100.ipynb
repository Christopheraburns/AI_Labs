{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages\n",
    "<ol>\n",
    "<li>[mxnet](http://mxnet.io/) for Neural Network creation and training and visualizations </li>\n",
    "<li>[numpy](http://www.numpy.org/) for data handling</li>\n",
    "<li>[matplotlib](https://matplotlib.org/) for additional vizualizations</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will download a small dataset to work with.  The inline comments explain the steps in this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the working dataset - unless it is already on the local machine (mxnet will tell us if we already have the data).\n",
    "fname=mx.test_utils.download('http://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data')\n",
    "\n",
    "# Use numpy to create a dataset - suitable for training - from the text file\n",
    "data = np.genfromtxt(fname, delimiter=',')[:,1:]\n",
    "\n",
    "# Use numpy again to create labels matching the dataset we created for training\n",
    "label = np.array([ord(l.split(',')[0])-ord('A') for l in open(fname, 'r')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take a peak at the structure of our data\n",
    "<ul>\n",
    "<li>The dataset contains black and white rectangular pixel displays of the 26 letters in the english alphabet</li>\n",
    "<li>By observing the <i>data.shape</i> property we see <b>(20000,16)</b>  This means there are 20K images with a resolution of 16 pixels\n",
    "<li>In the cell below we will look at a single data point</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape\n",
    "print(data.shape)\n",
    "\n",
    "sample = data[10]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may be wondering where the image of the characters are at.\n",
    "<ul>\n",
    "<li>What we see above is 16 \"primitive numerical attriubtes\"</li>\n",
    "<li>These attributes where \"scaled to fit into a range of integer values from 0 through 15</li>\n",
    "<li>This is a one way process that we cannot reverse.  The 16 digits have essentially become the signature of the character</li>\n",
    "<li>Here is what the first five data entries look like in the data file</li>\n",
    "<ol>\n",
    "    <li>T,2,8,3,5,1,8,13,0,6,6,10,8,0,8,0,8</li>\n",
    "    <li>I,5,12,3,7,2,10,5,5,4,13,3,9,2,8,4,10</li>\n",
    "    <li>D,4,11,6,8,6,10,6,2,6,10,3,7,3,7,3,9</li>\n",
    "    <li>N,7,11,6,6,3,5,9,4,6,4,4,10,6,10,2,8</li>\n",
    "    <li>G,2,1,3,1,1,8,6,6,6,6,5,9,1,7,5,10</li>\n",
    "</ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size tells mxnet how many characters to run through the network at once.\n",
    "batch_size = 32\n",
    "\n",
    "# Let's earmark 80% of our dataset for training \n",
    "ntrain = int(data.shape[0]*0.8)\n",
    "\n",
    "# We will split the data into training and validation \n",
    "train_iter = mx.io.NDArrayIter(data[:ntrain, :], label[:ntrain], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(data[ntrain:,:], label[ntrain:], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With our data now split into training and validation sets we are ready to build our network\n",
    "The cell below builds the layers of our MLP (multi-layer-perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare our netowrk definition\n",
    "net = mx.sym.Variable('data')\n",
    "\n",
    "# Add a fully connected layer\n",
    "net = mx.sym.FullyConnected(net, name='fc1', num_hidden=64)\n",
    "\n",
    "# Add a rectified linear unit (relu) layer - this defines the output of the node\n",
    "net = mx.sym.Activation(net, name='relu1', act_type=\"relu\")\n",
    "\n",
    "# add another fully connected layer\n",
    "net = mx.sym.FullyConnected(net, name='fc2', num_hidden=26)\n",
    "\n",
    "# add a softmax layer - this will normalize the output to be between 0 and 1\n",
    "net = mx.sym.SoftmaxOutput(net, name='softmax')\n",
    "\n",
    "# let's look at a conceptual view of our network\n",
    "mx.viz.plot_network(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the MXnet Module\n",
    "Training a Neural Network invloves many steps\n",
    "<ul>\n",
    "<li>How to feed input data</li>\n",
    "<li>Initialize model parameters</li>\n",
    "<li>Perform forward and backward passes through the network</li>\n",
    "<li>Update weights based on computed gradients</li>\n",
    "<li>Model training</li>\n",
    "</ul>\n",
    "Managing these steps can be cumbersome.  MXNet can modularize commonly used code in the [module](http://mxnet.io/tutorials/basic/module.html) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Contruct a module by specifiying the following parameters\n",
    "# Symbol = the Network definition - defined above with the \"net\" variable\n",
    "# Context = the device (or list of devices) to use for execution\n",
    "# Data_Names = the list of input data varaible names.\n",
    "# Label_names = the list of input label variable names.\n",
    "mod = mx.mod.Module(symbol=net,\n",
    "                   context=mx.cpu(),\n",
    "                   data_names=['data'],\n",
    "                   label_names=['softmax_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that the Module object is created we need to prepare the enviroment by allocating memory (bind)\n",
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "\n",
    "# Assign and initialize parameters\n",
    "mod.init_params(initializer=mx.init.Uniform(scale=.1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets recap what we have done before we actually train our model\n",
    "Thus far we have:\n",
    "<ul>\n",
    "<li>Acquired and loaded training data</li>\n",
    "<li>Split the data into training and validation data sets</li>\n",
    "<li>Defined our network</li>\n",
    "<li>Created a Module object to assist with the actual training of the network</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimizer (defaults to \"sgd\") MXNet supports the following optimizers:\n",
    "# NAG\n",
    "# RMSProp\n",
    "# Adam\n",
    "# AdaGrad\n",
    "# AdaDelta\n",
    "# DCASGD\n",
    "# SGLD\n",
    "mod.init_optimizer(optimizer='AdaGrad', optimizer_params=(('learning_rate', 0.1), ))\n",
    "\n",
    "# Create an evaluation metric based on the metric type\n",
    "# We will use accuracy = 'acc'\n",
    "metric = mx.metric.create('acc')\n",
    "\n",
    "va = []\n",
    "# The number of epochs is simply telling MXnet how many time to run our data through the network \n",
    "for epoch in range(4):\n",
    "    \n",
    "    # reset the cursor of our training iterator to the starting point\n",
    "    train_iter.reset()\n",
    "    \n",
    "    # clear previous epoch metric information\n",
    "    metric.reset()\n",
    "    \n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch, is_train=True)\n",
    "        mod.update_metric(metric, batch.label)\n",
    "        mod.backward()\n",
    "        mod.update()\n",
    "    va.append(metric.get()[1])\n",
    "    print('Epoch %d, Training %s' % (epoch, metric.get()))\n",
    "\n",
    "# Plot the graph of the networks accuracy        \n",
    "plt.plot(va)\n",
    "plt.axis([0,5, 0,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/stophere.jpg)\n",
    "\n",
    "When the instructor indicates it is time to continue - click [here](AML-100.ipynb) to go to the next lab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
